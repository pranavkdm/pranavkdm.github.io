
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>PointFlowHop</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>PointFlowHop</b>: Green and Interpretable Scene Flow <br> Estimation from Consecutive Point Clouds</br> 
                <small>
                    Submitted to APSIPA Transactions on Signal and Information Processing
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://pranavkdm.github.io/">
                          Pranav Kadam
                        </a>
                        </br>University of Southern California
                    </li>
                    <li>
                        <a href="http://mcl.usc.edu/people/graduate-students/#Jiahao_Gu">
                            Jiahao Gu
                        </a>
                        </br>University of Southern California
                    </li><br>
                    <li>
                        <a href="https://www.linkedin.com/in/shanliu">
                          Shan Liu
                        </a>
                        </br>Tencent Media Lab
                    </li>
                    <li>
                        <a href="https://mcl.usc.edu/people/cckuo/">
                          C.-C. Jay Kuo
                        </a>
                        </br>University of Southern California
                    </li>
                    
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="./PointFlowHop.pdf">
                            <image src="img/paper.PNG" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
<!--  
                        <li>
                            <a href="https://github.com/google/mipnerf">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4> 
                            </a>
                        </li> -->
                    </ul>
                </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    An efficient 3D scene flow estimation method called PointFlowHop is proposed in this work. 
                    PointFlowHop takes two consecutive point clouds and determines the 3D flow vectors for every point 
                    in the first point cloud. PointFlowHop decomposes the scene flow estimation task into a set of subtasks,
                    including ego-motion compensation, object association and object-wise motion estimation. It follows the 
                    green learning (GL) pipeline and adopts the feedforward data processing path. As a result, its underlying mechanism 
                    is more transparent than deep-learning (DL) solutions based on end-to-end optimization of network parameters. 
                    We conduct experiments on the stereoKITTI and the Argoverse LiDAR point cloud datasets and demonstrate that 
                    PointFlowHop outperforms deep-learning methods with a small model size and less training time. Furthermore, we 
                    compare the Floating Point Operations (FLOPs) required by PointFlowHop and other learning-based methods in inference, 
                    and show its big savings in computational complexity.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Method overview
                </h3>
                <image src="img/Architecture-PointFlowHop.png" class="img-responsive" alt="overview"><br>

            </div>
        </div>

<!-- 
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Related links
                </h3>
                <p class="text-justify">
                    <a href="https://en.wikipedia.org/wiki/Spatial_anti-aliasing">Wikipedia</a> provides an excellent introduction to spatial anti-aliasing techniques.
                </p>
            
                </p>
            </div>
        </div> -->
        
            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@inproceedings{kadam2023pointflowhop,
    title={PointFlowHop: Green and Interpretable Scene Flow
    Estimation from Consecutive Point Clouds},
    author={Kadam, Pranav and Gu, Jiahao and Liu, Shan and Kuo, C.-C. Jay},
    journal={arXiv preprint arXiv:2302.14193},
    year={2023}
    }
</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgement
                </h3>
                <p class="text-justify">
                This work was supported by Tencent Media Lab.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
